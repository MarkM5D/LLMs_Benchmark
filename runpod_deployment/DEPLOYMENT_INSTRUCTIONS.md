# RunPod H100 Deployment Instructions

## ğŸš€ Quick Start

1. **Upload to RunPod**
   ```bash
   # In RunPod terminal:
   cd /workspace
   # Upload this runpod_deployment folder here
   ```

2. **Run Setup**
   ```bash
   cd /workspace/runpod_deployment
   chmod +x runpod_startup.sh setup_env.sh
   ./runpod_startup.sh
   ```

3. **Verify H100 Setup**
   ```bash
   python3 h100_optimize.py
   ```

4. **Run Benchmarks**
   ```bash
   python3 run_all.py
   ```

## ğŸ“Š Expected Results

On H100 80GB you should see:
- vLLM: ~8000-12000 tokens/sec
- SGLang: ~7000-10000 tokens/sec  
- TensorRT-LLM: ~10000-15000 tokens/sec

## ğŸ”§ Troubleshooting

### GPU Not Detected
```bash
nvidia-smi
echo $CUDA_VISIBLE_DEVICES
```

### Build Errors
```bash
export CUDA_ARCHITECTURES=90
pip install --no-cache-dir --force-reinstall vllm
```

### Memory Issues
```bash
python3 -c "import torch; torch.cuda.empty_cache()"
```

## ğŸ“ File Structure in /workspace

```
/workspace/
â”œâ”€â”€ runpod_deployment/
â”‚   â”œâ”€â”€ setup_env.sh          # H100 optimized setup
â”‚   â”œâ”€â”€ h100_optimize.py      # H100 verification
â”‚   â”œâ”€â”€ run_all.py           # Main benchmark runner
â”‚   â”œâ”€â”€ benchmarks/          # Individual engine benchmarks
â”‚   â””â”€â”€ results/            # Benchmark outputs
```

## ğŸ¯ Success Indicators

âœ… H100 detected in h100_optimize.py
âœ… All 3 engines install successfully 
âœ… Benchmarks complete without errors
âœ… Results saved in benchmarks/results/
